{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371248db-6cd2-4daa-a426-25f4a9d98e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a4798-add2-490b-8778-0f281039b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2ba65-edee-4de4-b1fa-31abf2fc1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f84b8a-3aab-4aad-b460-84f15db34289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_image(name=\"1\"):\n",
    "    if len(name) > 8:\n",
    "        return name\n",
    "    else:\n",
    "        for i in range(8 - len(name)):\n",
    "            name = \"0\" + name\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0085a881-e2de-4734-8248-7cd614747de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train = []\n",
    "\n",
    "with open(\"train.csv\", newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        train.append({\n",
    "            \"memorability_score\": float(row['memorability_score']),\n",
    "            \"image\": row['image']\n",
    "        })\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53b59f-0a01-4152-a488-8fc4213b7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.txt\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "content = content[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f9ef2-7214-49a4-bc60-949bd5b07b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15c0d8-655a-4a9c-a8af-e3a4948a4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image constants\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecfc68f-c89c-47a3-8d3b-0c0a84ab98b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Constants defining train-test split\n",
    "train_start = 1\n",
    "train_end = 750\n",
    "val_end = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2780e8-24bb-46bd-824a-2018f904dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(batch_size=1, flag=\"train\"):\n",
    "    if flag == \"train\":\n",
    "        start = int(train_start / batch_size)\n",
    "        end = int(train_end / batch_size)\n",
    "    else:\n",
    "        start = int(train_end / batch_size)\n",
    "        end = int(val_end / batch_size)\n",
    "    x_train = np.zeros((batch_size, IMAGE_WIDTH, IMAGE_HEIGHT, 3), dtype=\"float32\")\n",
    "    y_train = np.zeros((batch_size, 1), dtype=\"float32\")\n",
    "\n",
    "    while True:\n",
    "        for i in range(start, end):\n",
    "            for j in range(batch_size):\n",
    "\n",
    "                image_file_detail = content[i * batch_size + j].split(\" \")\n",
    "\n",
    "                y_train[j, :] = float(image_file_detail[1])\n",
    "                path = \"images/\" + image_file_detail[0]\n",
    "\n",
    "                # preprocess the image\n",
    "                img = keras.utils.load_img(path)\n",
    "                img = img.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "                img = keras.utils.img_to_array(img)\n",
    "                img = preprocess_input(img, mode=\"tf\")\n",
    "                x_train[j, : img.shape[0], : img.shape[1], :] = img\n",
    "\n",
    "            # return train data\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac029c8-0ddf-461a-8392-bf4e312bfa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    my_model = Sequential()\n",
    "\n",
    "    # Convolution layers\n",
    "    my_model.add(\n",
    "        Conv2D(\n",
    "            32, (3, 3), input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3), activation=\"relu\"\n",
    "        )\n",
    "    )\n",
    "    my_model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    my_model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    my_model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    my_model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    my_model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    my_model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    my_model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    my_model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    my_model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Dropout and Flatten layer\n",
    "    my_model.add(Dropout(0.2))\n",
    "    my_model.add(Flatten())\n",
    "\n",
    "    # Fully Connected layers\n",
    "    my_model.add(Dense(128, activation=\"relu\"))\n",
    "    my_model.add(Dropout(0.2))\n",
    "    my_model.add(Dense(64, activation=\"relu\"))\n",
    "    my_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    my_model.summary()\n",
    "\n",
    "    # Compile model\n",
    "    my_model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09dc132-7b9d-4b0f-aea4-5e20cde2b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate base model\n",
    "model = baseline_model()\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 16\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "# Callback function to save the epoch with least val_loss\n",
    "filepath = \"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor=\"val_acc\", verbose=0, save_best_only=True, mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee22c0-5fe4-4dcc-81e0-952b1420c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, fit the model to data\n",
    "history = model.fit(\n",
    "    gen(batch_size=batch_size),\n",
    "    steps_per_epoch=(train_end - train_start) / batch_size,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint],\n",
    "    validation_data=gen(batch_size=batch_size, flag=\"val\"),\n",
    "    validation_steps=(val_end - train_end) / batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba6d893-8680-453d-acc6-7a0890a87b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"semmem.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6521da03-f576-483f-b650-f4d3b9dc8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 6))\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.savefig(\"plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97e706-0569-48bd-a571-11088de736d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
